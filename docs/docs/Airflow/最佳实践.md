# 尽量使用分布式架构和容器
**把Airflow的各个组件分开，尤其是Scheduler和Worker分开，有利于系统的稳定性**

Scheduler如果拿不到足够资源，可能出现：

+ 任务已经完成，但并未被标记为”完成“
+ 任务正在执行，但已经和scheduler失联，导致scheduler重新启动了同一个任务，出现奇怪的问题

推荐添加scheduler的监控



# 任务的幂等性
**在设计每一个任务的时候，尽量做到可以重复多次运行，即使在运行过程中被打断了，下次运行依然不会出问题**

Airflow中的任务，被打断是难以避免的

增量更新保持幂等性的可行方法：

1. 按分区覆盖写入。适合按时间更新的场景
2. 使用checkpoint。需要外部文件来维护checkpoint



# 多实现自己的Operator
在ETL同步文件时比较有用，可以将外部的下载数据的api封装成Operator



# 定期清理元数据库
数据库中有些表会保存每一次任务的信息，日积月累表就会变得越来越大，导致搜索变慢

例如：每个task的xcom都会被保存到数据库，需要谨慎使用，不用可以设置disable



# 注意资源管理
1. Variable不要滥用，会消耗数据库连接资源。Variable不要放在文件的顶层，避免在解析文件到UI页面的时候被调用
2. DAG定义文件中，不应该用资源昂贵的操作，因为Airflow非常频繁地扫描DAG文件（默认每分钟一次）

