# hadoop
修改全局环境变量

hadoop-env.sh

core-site.xml

yarn-site.xml

hdfs-site.xml

mapred-site.xml

删除namenode、datanode、tmp文件，重新格式化hdfs

在hdfs里面创建一个spark的日志路径





# hive
替换hadoop的guava到hive里面：hadoop/share/common

上传mysql的jar包

修改全局环境变量

【可选】初始化mysql的元数据、解决中文乱码

把hadoop的aws的jar组件复制到hive的lib里面：hadoop/share/hadoop/tools/lib

aws-java-sdk-bundle-xxx.jar

hadoop-aws-xxx.jar

hive on spark只能一个beeline用，会造成yarn队列占用问题

todo：解决报错复杂sql导致s3错误

todo：增加单独的队列运行hive on spark

# spark
with hadoop版本：确保hadoop和spark里的hadoop版本完全相同。如果不相同，需要替换spark的jar包中的hadoop-common和guava。

without hadoop版本：

1. 复制hive-site.xml到spark的conf下面
2. 在spark-env.sh添加hadoop的classpath
3. 把hive的hive-*的jar包复制到spark的jar文件中。
4. 下载spark-hive.jar和spark-hive-thriftserver.jar，复制到spark的jar包（最后的版本号对应spark的版本号）
5. 把hadoop的guava复制过来

遇到问题：

报错

<font style="color:rgb(31, 35, 40);">NoSuchMethodError: SemaphoredDelegatingExecutor while writing files to S3</font>

替换spark的jar目录下的hadoop-common

报错：

<font style="color:rgb(31, 35, 40);">NoSuchMethodError: org.google.common.base.preconditions.checkargument</font>

<font style="color:rgb(31, 35, 40);">替换spark的jar目录下的guava</font>

## spark连接Cassandra
首先要下载驱动<font style="color:rgb(12, 13, 14);"> </font>[spark-cassandra-connector-assembly](https://mvnrepository.com/artifact/com.datastax.spark/spark-cassandra-connector-assembly)<font style="color:rgb(12, 13, 14);">.jar，放入spark的jars文件夹下</font>

<font style="color:rgb(12, 13, 14);">报错0：failed to find data source: org.apache.spark.sql.cassandra. please find packages at ....</font>

<font style="color:rgb(12, 13, 14);">解决方式：没装驱动，需要下载驱动</font>

报错1：<font style="color:rgb(12, 13, 14);">Pyspark cassandra connector NoclassDefFoundError, util/logging</font>

解决方式：下载驱动<font style="color:rgb(12, 13, 14);"> </font>[spark-cassandra-connector-assembly](https://mvnrepository.com/artifact/com.datastax.spark/spark-cassandra-connector-assembly)<font style="color:rgb(12, 13, 14);">.jar，而不是只下载spark-cassandra-connector.jar</font>

[https://stackoverflow.com/questions/72587210/pyspark-cassandra-connector-noclassdeffounderror-util-logging](https://stackoverflow.com/questions/72587210/pyspark-cassandra-connector-noclassdeffounderror-util-logging)

报错2：<font style="color:rgb(12, 13, 14);">java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler</font>

<font style="color:rgb(12, 13, 14);">解决方式：</font>

# airflow
替换mysql数据库时

数据库连接url改成：mysql+pymysql:// ，不要用mysqldb和mysqlconnector

修改顺序调度器为并发调度

